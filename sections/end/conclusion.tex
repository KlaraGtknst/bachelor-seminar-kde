\section{Conclusion and Outlook}
\label{sec:conclusion}

The study of \acp{SNN}, especially with regard to efficient learning procedures poses a interesting insight in the possibilities of modeling
systems on the human brain.
Concerning the difficulties of training a model which works with input values and their temporal dependencies researchers have already made 
impressive efforts.
The work of \cite{SNN} proposes an unsupervised approach with formidable performace in a variety of situations.
The authors of \cite{SNN} and \cite{Synaptic_plasticity} also emphasise the energy efficience of \acp{SNN} on neuromorphic hardware.

Besides this example of an unsupervised approach there is a variety of supervised methods to train a \ac{SNN}, 
for instance \ac{ANN}-\ac{SNN} conversion from \cite{DIET_SNN}.
Even though existing approaches perform well, the authors emphasise shortcomings and potential of further research.
\textcolor{red}{Bsp. offene Fragen}

This paper neglects the topic neuromorphic hardware.
Other work, such as \cite{Synaptic_plasticity}, 
cover several different implementations and offer a discussion about challenges (e.g. memory elements) and adchievements 
(e.g. successful synaptic rule implementations in hardware) in this area.
The hardware seems to be in need of more improvements to be applicable to real-world problems.

wdhl wie gut es ist\\
was kommt noch?\\
wie zu verbessern?