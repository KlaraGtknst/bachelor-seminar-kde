\section{Results}
\label{sec:result}
% STDP-like paper
The model was evaluated on the MNIST dataset.
According to the authors of \cite{STDP_like}, the dataset is a suitable Benchmark for the \ac{SNN} model, 
since it provides different difficulty levels of categorization.
The authors of \cite{STDP_like} emphasise that the MNIST dataset less complex than biological vision.

The addition to accuracy with regard to the classification of the MNIST dataset impulses \cite{STDP_like} presents \ac{RT} distributions.
\ac{RT} is defined as the time between the presentation of a stimulus and the response (i.e. the first pool to reach the descision pool).
Usually, the \ac{RT} of misclassified digits is higher than the \ac{RT} of correctly classified digits.
However, the network also makes fast errors.
The results were verified with the Kolmogorov-Smirnov test, 
indicating that the correctly and misclassified \ac{RT} distributions are significantly different, 
whereas as the distributions for stimuli from the training and test set were not.

The authors of \cite{STDP_like} compare the performance of the \ac{SNN} model for different training set sizes $n_{train}$.
They find that the network is able to generalize well if the training set size is sufficiently large.
The optimum training set size $n_{train} = 1000$ produced not remarkably higher misclassifaction rates than bigger training set sizes.
The most frequent misclassification was the digit nine as a zero.



% Original STDP paper
Benchmark\\
zugrundeliegende Daten