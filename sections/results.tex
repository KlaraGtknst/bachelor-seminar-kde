\section{Results}
\label{sec:result}
The model was evaluated on the MNIST dataset.
According to the authors of \cite{STDP_like}, the dataset is a suitable Benchmark for the \ac{SNN} model, 
since it provides different difficulty levels of categorization.
The authors of \cite{STDP_like} emphasise that the MNIST dataset less complex than biological vision.

The addition to accuracy with regard to the classification of the MNIST dataset impulses \cite{STDP_like} presents \ac{RT} distributions.
\ac{RT} is defined as the time between the presentation of a stimulus and the response (i.e. the first pool to reach the descision pool).

The authors of \cite{STDP_like} compare the performance of the \ac{SNN} model for different training set sizes $n_{train}$.
They find that the network is able to generalize well if the training set size is sufficiently large.
The optimum training set size $n_{train} = 1000$ produced not significantly higher misclassifaction rates than bigger training set sizes.

Benchmark\\
zugrundeliegende Daten