\begin{abstract}
The human brain is particularly good at pattern recognition requiring little power. 
Due to this fact, scientists are trying to understand the brain and build systems to model it.
Since conventional \acfi{ANN} often use backpropagation and are thus, biologically implausible or require a lot of power to do computations researchers have started focusing on implementing alternatives such as \acfi{SNN}.

A \ac{SNN}'s neuron fires if its membrane potential exceeds a certain (adaptable) threshold. 
The membrane's potential is calculated by the sum of incoming spikes with respect their timing and thus, the exponential decay of the potential.
This process is biologically plausible.
Synapses are modelled by the connections between neurons.
The importance/influence of a synapse is represented by the weight of the connection and altered during training to disconnect neurons from those that have little influence on their spiking activity.
The usage of \hMethod{} (i.e. adaptive membrane threshold and limiting the firing rate of neurons) prevents single neurons from firing all the time and enables the neurons to learn/adapt to different input patterns.

The approach of this paper is tested on the MNIST dataset.  
TODO

\keywords{unsupervised learning \and spike-timing-dependent \and biologically plausible \and lateral inhibition \and adaptive spiking threshold \and homoeostasis}
\end{abstract}